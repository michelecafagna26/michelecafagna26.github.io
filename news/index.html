<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>News | Michele Cafagna</title> <meta name="author" content="Michele Cafagna"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon_io/favicon.ico?f8c630af8ea140dcb8f5e5275c70accf"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://michelecafagna26.github.io//news/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?3dd82e91913a2c1265c0f80e41ff39e2"></script> <script src="/assets/js/dark_mode.js?6458e63976eae16c0cbe86b97023895a"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">MicheleÂ </span>Cafagna</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">Short CV</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">News</h1> <p class="post-description"></p> </header> <article> <div class="news"> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Mar 18, 2024</th> <td> Joined <a href="https://okra.ai/" rel="external nofollow noopener" target="_blank"> Okra.ai</a> as NLP Data Scentist,ğŸ‡³ğŸ‡± ğŸ‰ </td> </tr> <tr> <th scope="row">Jan 16, 2024</th> <td> Our paper<a href="https://openreview.net/forum?id=liuqDwmbQJ" rel="external nofollow noopener" target="_blank"> â€œViLMA: A Zero-Shot Benchmark for Linguistic and Temporal Grounding in Video-Language Modelsâ€</a> , accepted @ICLR 2024 , Vienna,ğŸ‡¦ğŸ‡¹ ğŸ‰ </td> </tr> <tr> <th scope="row">Oct 10, 2023</th> <td> Reviewer for<a href="https://lrec-coling-2024.org/" rel="external nofollow noopener" target="_blank"> COLING-LREC2024</a>, Torino, ğŸ‡®ğŸ‡¹ </td> </tr> <tr> <th scope="row">Sep 11, 2023</th> <td> Presented the poster<a href="https://sigdialinlg2023.github.io/static/posters/INLG2023/13.pdf" rel="external nofollow noopener" target="_blank">â€œHL Dataset: Visually-grounded Description of Scenes, Actions and Rationalesâ€ </a><a href="https://inlg2023.github.io/" rel="external nofollow noopener" target="_blank"> @INLG 2023 </a> , Prague, ğŸ‡¨ğŸ‡¿ </td> </tr> <tr> <th scope="row">Sep 4, 2023</th> <td> Our paper <a href="https://www.frontiersin.org/articles/10.3389/frai.2023.1220476/abstract" rel="external nofollow noopener" target="_blank"> â€œInterpreting Vision and Language Generative Models with Semantic Visual Priorsâ€</a> published in <a href="https://www.frontiersin.org/research-topics/48440/explainable-ai-in-natural-language-processing" rel="external nofollow noopener" target="_blank"> @Frontiers in AI Journal </a> </td> </tr> <tr> <th scope="row">Aug 6, 2023</th> <td> Reviewer for<a href="https://ecai2023.eu/" rel="external nofollow noopener" target="_blank"> 26th European Conference on Artificial Intelligence ECAI 2023</a>, KrakÃ³w, ğŸ‡µğŸ‡± </td> </tr> <tr> <th scope="row">Jul 13, 2023</th> <td> Our paper <a href="https://arxiv.org/abs/2302.12189?context=cs.CL" rel="external nofollow noopener" target="_blank">â€œHL Dataset: Visually-grounded Description of Scenes, Actions and Rationalesâ€ </a>, accepted <a href="https://inlg2023.github.io/" rel="external nofollow noopener" target="_blank"> @INLG 2023 </a> , Prague, ğŸ‡¨ğŸ‡¿ ğŸ‰ </td> </tr> <tr> <th scope="row">Jun 18, 2023</th> <td> Reviewer for<a href="https://synalp.gitlabpages.inria.fr/mmnlg2023/" rel="external nofollow noopener" target="_blank"> MMNLG2023 co-located with INLG 2023</a>, Prague, ğŸ‡¨ğŸ‡¿ </td> </tr> <tr> <th scope="row">Jun 14, 2023</th> <td> Reviewer for<a href="https://2023.emnlp.org/" rel="external nofollow noopener" target="_blank"> EMNLP2023</a>, Singapore, ğŸ‡¸ğŸ‡¬ </td> </tr> <tr> <th scope="row">May 8, 2023</th> <td> Proud to be among the outstanding reviewers who served <a href="https://2023.eacl.org/" rel="external nofollow noopener" target="_blank"> @EACL 2023</a>, Dubrovnik, ğŸ‡­ğŸ‡· </td> </tr> <tr> <th scope="row">Apr 28, 2023</th> <td> Our paper <a href="https://arxiv.org/pdf/2304.14986.pdf" rel="external nofollow noopener" target="_blank"> â€œInterpreting Vision and Language Generative Models with Semantic Visual Priorsâ€</a>, is online ğŸ‰. ğŸ—ƒï¸ Code available <a href="https://github.com/michelecafagna26/vl-shap" rel="external nofollow noopener" target="_blank">here</a> </td> </tr> <tr> <th scope="row">Feb 27, 2023</th> <td> Member of the review committee <a href="https://2023.sigdial.org/" rel="external nofollow noopener" target="_blank"> @SIGDIAL &amp; INLG 2023</a>, Prague, ğŸ‡¨ğŸ‡¿ </td> </tr> <tr> <th scope="row">Feb 23, 2023</th> <td> Our paper <a href="https://arxiv.org/pdf/2302.12189.pdf" rel="external nofollow noopener" target="_blank"> â€œHL Dataset: Grounding High-Level Linguistic Concepts in Visionâ€</a>, is online ğŸ‰ </td> </tr> <tr> <th scope="row">Dec 15, 2022</th> <td> Member of the review committee <a href="https://2023.aclweb.org/" rel="external nofollow noopener" target="_blank"> @ACL 2023</a>, Toronto, ğŸ‡¨ğŸ‡¦ </td> </tr> <tr> <th scope="row">Dec 15, 2022</th> <td> Attended NL4XAI Training event on Evaluation and Reproducibility in NLG <a href="https://www.uu.nl/en" rel="external nofollow noopener" target="_blank">@University of Utrecht</a>, Utrecht, ğŸ‡³ğŸ‡±. </td> </tr> <tr> <th scope="row">Nov 15, 2022</th> <td> Member of the review committee for the track Language Grounding and Multi-Modality <a href="https://2023.eacl.org/" rel="external nofollow noopener" target="_blank"> @EACL 2023</a>, Dubrovnik, ğŸ‡­ğŸ‡· </td> </tr> <tr> <th scope="row">Nov 8, 2022</th> <td> Our paper <a href="https://arxiv.org/pdf/2211.04971.pdf" rel="external nofollow noopener" target="_blank">â€œUnderstanding Cross-modal Interactions in V&amp;L Models that Generate Scene Descriptionsâ€ </a>, accepted <a href="https://induction-of-structure.github.io/emnlp2022/call_for_papers" rel="external nofollow noopener" target="_blank">@UM-IoS Workshop</a><a href="https://2022.emnlp.org/" rel="external nofollow noopener" target="_blank"> EMNLP 2022, ğŸ‡¦ğŸ‡ª</a> ğŸ‰ </td> </tr> <tr> <th scope="row">Oct 1, 2022</th> <td> Visiting the<a href="https://www.orange-business.com/en/corporate/innovation-is-what-drives-us" rel="external nofollow noopener" target="_blank">ğŸŠOrange Innovation Labs</a>, Lannion, ğŸ‡«ğŸ‡· </td> </tr> <tr> <th scope="row">Aug 15, 2022</th> <td> Reviewer for<a href="https://www.sciencedirect.com/journal/computer-speech-and-language" rel="external nofollow noopener" target="_blank"> Computer Speech &amp; Language Journal</a> </td> </tr> <tr> <th scope="row">Jul 15, 2022</th> <td> Reviewer for<a href="https://coling2022.org/" rel="external nofollow noopener" target="_blank"> COLING 2022, Gyeongju</a>, ğŸ‡°ğŸ‡· </td> </tr> <tr> <th scope="row">Jun 9, 2022</th> <td> Poster on â€œGrounding Language in Vision for Understanding and Generationâ€<a href="https://www.uu.nl/en/events/meet-the-people-of-human-centered-ai" rel="external nofollow noopener" target="_blank">@Meet the People of Human-Centered AI</a>, Utrecht, ğŸ‡³ğŸ‡±&lt;/a&gt; </td> </tr> <tr> <th scope="row">Jun 7, 2022</th> <td> Presented â€œCan Vision-Language models generate scene descriptions?â€ @ NLG in the Lowland workshop, Tilburg&lt;/a&gt;, ğŸ‡³ğŸ‡± </td> </tr> <tr> <th scope="row">May 22, 2022</th> <td> Attendig + Poster presentation <a href="https://induction-of-structure.github.io/emnlp2022/call_for_papers" rel="external nofollow noopener" target="_blank">@UM-IoS Workshop, </a><a href="https://2022.emnlp.org/" rel="external nofollow noopener" target="_blank"> EMNLP 2022 </a>, Abu Dhabi, ğŸ‡¦ğŸ‡ª </td> </tr> <tr> <th scope="row">May 22, 2022</th> <td> Attendig + Poster presentation <a href="https://www.2022.aclweb.org/" rel="external nofollow noopener" target="_blank">@ACL2022</a>, Dublin, ğŸ‡®ğŸ‡ª </td> </tr> <tr> <th scope="row">Apr 25, 2022</th> <td> Our paper <a href="https://arxiv.org/pdf/2112.07566.pdf" rel="external nofollow noopener" target="_blank"> â€œVALSE: A Task-Independent Benchmark for Vision and Language Models Centered on Linguistic Phenomenaâ€</a>, accepted @ <a href="https://www.2022.aclweb.org/" rel="external nofollow noopener" target="_blank">ACL2022 ğŸ‡®ğŸ‡ª</a> ğŸ‰ </td> </tr> <tr> <th scope="row">Apr 19, 2022</th> <td> <ul> <li>Attended NL4XAI Training event on NLG and Explainable NLG <a href="https://www.loria.fr/en/" rel="external nofollow noopener" target="_blank">@Loria</a>, Nancy, ğŸ‡«ğŸ‡·.</li> <li>Presented: Grounding Language in Vision for Understanding and Generation</li> </ul> </td> </tr> <tr> <th scope="row">Jan 31, 2022</th> <td> Mphil to Phd Transfer <a href="https://www.um.edu.mt/" rel="external nofollow noopener" target="_blank">@University of Malta</a>, ğŸ‡²ğŸ‡¹ &lt;/a&gt; </td> </tr> <tr> <th scope="row">Jan 20, 2022</th> <td> Attended the <a href="http://lig-alps.imag.fr/" rel="external nofollow noopener" target="_blank">ALPS 2022, (online)</a> winter school with poster<a href="https://drive.google.com/file/d/1uly82lEH2dCHO52ZVI1-Zj2DWzzAdgJ7/view?usp=sharing" rel="external nofollow noopener" target="_blank"> presentation</a> </td> </tr> <tr> <th scope="row">Jan 2, 2022</th> <td> Visiting the <a href="https://www.uu.nl/en/research/intelligent-software-systems/natural-language-processing" rel="external nofollow noopener" target="_blank">NLP group @University of Utrecht</a> </td> </tr> <tr> <th scope="row">Nov 7, 2021</th> <td> Attended <a href="https://2021.emnlp.org/" rel="external nofollow noopener" target="_blank">EMNLP 2021 (online)</a> </td> </tr> <tr> <th scope="row">Oct 26, 2021</th> <td> Attended NL4XAI Training event on prototyping and testing and technology commercialization and business planning <a href="https://www.utwente.nl/en/" rel="external nofollow noopener" target="_blank">@University of Twente</a>, Enschede, ğŸ‡³ğŸ‡±. </td> </tr> <tr> <th scope="row">Sep 15, 2021</th> <td> <a href="https://medium.com/aptus-ai/have-you-ever-talked-to-geppetto-f04f87e77176" rel="external nofollow noopener" target="_blank">Story</a> published on medium for Aptus.ai </td> </tr> <tr> <th scope="row">Sep 13, 2021</th> <td> Journal published at <a href="https://journals.openedition.org/ijcol/" rel="external nofollow noopener" target="_blank">IJCol</a> </td> </tr> <tr> <th scope="row">Sep 7, 2021</th> <td> <a href="https://nl4xai.eu/" rel="external nofollow noopener" target="_blank">NL4XAI</a> Annual Meeting, Barcelona, ğŸ‡ªğŸ‡¸ </td> </tr> <tr> <th scope="row">Jul 15, 2021</th> <td> Reviewer for <a href="https://inlg2021.github.io/pages/calls.html" rel="external nofollow noopener" target="_blank"> INLG2021, </a>Aberdeen, ğŸ‡¬ğŸ‡§ </td> </tr> <tr> <th scope="row">Jun 21, 2021</th> <td> Panel Presentation <a href="http://nldb2021.sb.dfki.de/" rel="external nofollow noopener" target="_blank">@NLDB2021</a> </td> </tr> <tr> <th scope="row">May 12, 2021</th> <td> Our paper <a href="https://arxiv.org/pdf/2109.07301.pdf" rel="external nofollow noopener" target="_blank"> â€œWhat Vision-Language Models â€˜Seeâ€™ when they See Scenesâ€</a>, is online ğŸ‰. </td> </tr> </table> </div> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> Â© Copyright 2024 Michele Cafagna. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>